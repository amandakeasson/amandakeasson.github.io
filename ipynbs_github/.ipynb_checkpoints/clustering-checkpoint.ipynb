{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/AmandaE/anaconda/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "## import\n",
    "\n",
    "from sklearn.cluster import AffinityPropagation as affinity\n",
    "\n",
    "from __future__ import division # to get integer division\n",
    "import pickle\n",
    "\n",
    "import scipy.io as sio\n",
    "from nilearn import plotting, image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats, linalg, ndimage, signal\n",
    "from pylab import *\n",
    "\n",
    "# from sklearn import datasets\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import Lasso, LassoCV\n",
    "from sklearn.cross_validation import KFold, cross_val_score, permutation_test_score, train_test_split, StratifiedKFold\n",
    "from sklearn.dummy import DummyClassifier\n",
    "import sklearn.feature_selection\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, RFE\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.externals import joblib\n",
    "# from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from nilearn.decomposition.canica import CanICA\n",
    "from nilearn.plotting import plot_stat_map #, show, plot_prob_atlas\n",
    "from nilearn.image import iter_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plotting, smoothing, detrending\n",
    "firstvol = image.index_img(<imgfile>,0)\n",
    "smooth_img = image.smooth_img(firstvol)\n",
    "display = plotting.plot_glass_brain(smooth_img,fwhm=6)\n",
    "smooth_img.to_filename(“<filename>”)\n",
    "display.close()\n",
    "display.savefig\n",
    "plt.plot(x,y)\n",
    "tsmooth = ndimage.gaussian_filter(t,sigma=2)\n",
    "t_detrend = signal.detrend(t)\n",
    "\n",
    "# Loop over each image\n",
    "for volume in image.iter_img(“<nifti name>”)\n",
    "    smoothed_img = image.smooth_img(volume, fwhm=6) # finish for loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#################################### ML SETUP ######################################\n",
    "mypath = '/Users/AmandaE/Documents/MATLAB/projects/abide/abide_pls/new_dosenbach/'\n",
    "filename = mypath + 'conn_static_Kids_CCS_dos_filtnoglob'\n",
    "\n",
    "# Load MATLAB files\n",
    "mat = sio.loadmat(filename)\n",
    "mat1 = mat['connmat_all']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-d600475a11f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mn_clusters_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster_centers_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Estimated number of clusters: %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mn_clusters_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "## affinity clustering\n",
    "\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "\n",
    "# compute affinity propagation\n",
    "af = AffinityPropagation(preference=-50,max_iter=1000).fit(mat1[1:5,10])\n",
    "cluster_centers_indices = af.cluster_centers_indices_\n",
    "labels = af.labels_\n",
    "\n",
    "n_clusters_ = len(cluster_centers_indices)\n",
    "\n",
    "print('Estimated number of clusters: %d' % n_clusters_)\n",
    "\n",
    "# print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels_true, labels))\n",
    "# print(\"Completeness: %0.3f\" % metrics.completeness_score(labels_true, labels))\n",
    "# print(\"V-measure: %0.3f\" % metrics.v_measure_score(labels_true, labels))\n",
    "# print(\"Adjusted Rand Index: %0.3f\"\n",
    "      # % metrics.adjusted_rand_score(labels_true, labels))\n",
    "# print(\"Adjusted Mutual Information: %0.3f\"\n",
    "      # % metrics.adjusted_mutual_info_score(labels_true, labels))\n",
    "# print(\"Silhouette Coefficient: %0.3f\"\n",
    "      # % metrics.silhouette_score(X, labels, metric='sqeuclidean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#################################### CLASSIFIERS ######################################\n",
    "\n",
    "# SVC\n",
    "svc = SVC(kernel = ‘linear’, C=1.)\n",
    "digits = datasets.load_digits()\n",
    "data = digits.data\n",
    "labels = digits.target\n",
    "svc.fit(data[:-10], labels[:-10])\n",
    "svc.predict(data[-10:])\n",
    "coef = svc.coef_\n",
    "coef_img = featsel.inverse_transform(coef)\n",
    "\n",
    "# Linear SVC\n",
    "lsvc = LinearSVC(C=1., penalty = \"l1\", dual=False)\n",
    "\n",
    "# LDA\n",
    "lda = LDA()\n",
    "anova_lda = Pipeline([('anova', feature_selection), ('LDA', lda)])\n",
    "\n",
    "#SVM-RFE\n",
    "rfe = RFE(SVC(kernel='linear', C=1.), <nfeat>, step=0.25) # can change step size\n",
    "rfe_svc = Pipeline([('rfe',rfe), ('svc',svc)])\n",
    "cv_scores = cross_val_score(rfe_svc,X,labels, cv=cv)\n",
    "\n",
    "# Lasso\n",
    "lasso = linear_model.LassoCV()\n",
    "\n",
    "# LASSOCV\n",
    "lasso_cv = sklearn.linear_model.LassoCV(alphas=.1)\n",
    "k_fold = KFold(46,3)\n",
    "scores = list()\n",
    "for k, (train,test) in enumerate(k_fold):\n",
    "    lasso_cv.fit(matS[train], labels[train])\n",
    "        lasso_cv.score(matS[test], labels[test])\n",
    "\n",
    "# Decision tree with feature importance\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X,y)\n",
    "clf.score(X,y)\n",
    "importances = clf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "for i in range(10):\n",
    "    print \"{} feature no.{} ({})\".format(i+1,indices[i],importances[indices[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#################################### FEATURE SELECTION ######################################\n",
    "\n",
    "# RFE\n",
    "rfe = RFE(estimator=svc,n_features_to_select=1,step=1)\n",
    "rfe.fit(X,y)\n",
    "ranking = rfe.ranking_\n",
    "\n",
    "# RFE\n",
    "rfe = RFE(estimator = lsvc, n_features_to_select = 100, step=.1)\n",
    "rfecv = RFECV(estimator = lsvc, n_features_to_select = 100, step = 100)\n",
    "mlmat = matS\n",
    "featscores = np.zeros([np.shape(mlmat)[0],np.shape(mlmat)[1]])\n",
    "scores = list()\n",
    "inds = np.arange(46)\n",
    "for i in range(46):\n",
    "    print \"Subject\", i+1\n",
    "        inds2 = (inds!=i)\n",
    "        X = mlmat[inds2,:]\n",
    "        y = labels[inds2]\n",
    "        Xtrain, Xcv, Ytrain, Ycv = train_test_split(matD2,labels2,test_size = 0.33, random_state=42)\n",
    "        rfecv.fit(Xtrain,Ytrain)\n",
    "        feats = find(rfe.ranking_==1)\n",
    "        test = mlmat[i,:].reshape(1,-1)\n",
    "        tempscore = rfe.predict(test)\n",
    "        scores.append(tempscore[0])\n",
    "        featscores[i,feats] = 1\n",
    "\n",
    "# RFECV\n",
    "rfecv = RFECV(estimator=svc, step=.25, cv=StratifiedKFold(y,2), scoring='accuracy')\n",
    "rfecv.fit(X,y)\n",
    "rfecv.n_features_\n",
    "plt.figure()\n",
    "plt.plot(range(1,len(rfecv.grid_scores_) +1), rfecv.grid_scores_)\n",
    "plt.show()\n",
    "\n",
    "# Feature selection using ANOVA\n",
    "feature_selection = SelectKBest(f_classif, k=500)\n",
    "anova_svc = Pipeline([('anova', feature_selection), ('svc', svc)])\n",
    "anova_svc.fit(X,labels)\n",
    "y_pred = anova_svc.predict(X)\n",
    "\n",
    "# Test a range of features\n",
    "kvals = np.arange(200)\n",
    "scores_all = np.zeros((200,100))\n",
    "svc = SVC(kernel=\"rbf\", C=1.)\n",
    "for r in range(100):\n",
    "    print \"Iteration =\", r+1\n",
    "    for i in range(200):\n",
    "        # print \"# features = \", i+1\n",
    "        featsel = SelectKBest(f_classif,k=kvals[i]+1)\n",
    "        anova_svc = Pipeline([('anova', featsel), ('svc',svc)])\n",
    "        cv = KFold(n=46,n_folds=4,shuffle=True)\n",
    "        scores = cross_val_score(anova_svc,matD2,labels,cv=cv)\n",
    "    scores_all[:,r] = np.mean(scores)\n",
    "\n",
    "# Test a specific # of features\n",
    "featsel = SelectKBest(f_classif,k=56)\n",
    "anova_svc = Pipeline([('anova', featsel), ('svc',lsvc)])\n",
    "cv = KFold(n=46,n_folds=46,shuffle=True)\n",
    "scores = cross_val_score(anova_svc,matSD2,labels2,cv=cv)\n",
    "np.mean(scores)\n",
    "\n",
    "# Make list of important features\n",
    "kvals = np.arange(200)\n",
    "scores = list()\n",
    "featscores = np.zeros([np.shape(mlmat)[0],np.shape(mlmat)[1]])\n",
    "mlmat = matS\n",
    "featsel = SelectKBest(f_classif,k=56)\n",
    "anova_svc = Pipeline([('anova', featsel), ('svc',lsvc)])\n",
    "for i in range(46):\n",
    "    print \"Subject\", i+1\n",
    "        inds2 = (inds!=i)\n",
    "        X = mlmat[inds2,:]\n",
    "        y = labels2[inds2]\n",
    "        anova_svc.fit(X,y)\n",
    "        feats = lsvc.coef_\n",
    "        feats = featsel.inverse_transform(feats)\n",
    "        # featscores[i,feats] = 1\n",
    "        featscores[i,:] = feats\n",
    "        test = mlmat[i,:].reshape(1,-1)\n",
    "        tempscore = anova_svc.predict(test)\n",
    "        scores.append(tempscore[0])\n",
    "\n",
    "# Select from model\n",
    "mlmat = matSs\n",
    "featscores = np.zeros([np.shape(mlmat)[0],np.shape(mlmat)[1]])\n",
    "scores = list()\n",
    "inds = np.arange(46)\n",
    "for i in range(46):\n",
    "    print \"Subject\", i+1\n",
    "        inds2 = (inds!=i)\n",
    "        X = mlmat[inds2,:]\n",
    "        y = labels2[inds2]\n",
    "        lsvc = LinearSVC(C=1., penalty=\"l1\", dual=False).fit(X,y)\n",
    "        model = SelectFromModel(lsvc,prefit=True)\n",
    "        test = mlmat[i,:].reshape(1,-1)\n",
    "        test= model.transform(test)\n",
    "        lsvc = LinearSVC(C=1., penalty=\"l1\", dual=False).fit(model.transform(X),y)\n",
    "        tempscore = lsvc.predict(test)\n",
    "        scores.append(tempscore[0])\n",
    "        feats = find(rfe.ranking_==1)\n",
    "        featscores[i,feats] = 1\n",
    "\n",
    "# Full inner + outer CV\n",
    "kvals = np.arange(200)\n",
    "scores_all = np.zeros((200,100))\n",
    "svc = SVC(kernel=\"rbf\", C=1.)\n",
    "\n",
    "for r in range(100):\n",
    "    print \"Iteration =\", r+1\n",
    "    XtrainT, Xtest, YtrainT, Ytest = train_test_split(matS,labels,test_size=.25,random_state=42)\n",
    "    for i in range(200):\n",
    "        # print \"# features = \", i+1\n",
    "        featsel = SelectKBest(f_classif,k=kvals[i]+1)\n",
    "        anova_svc = Pipeline([('anova', featsel), ('svc',svc)])\n",
    "        cv = KFold(n=46,n_folds=4,shuffle=True)\n",
    "        scores = cross_val_score(anova_svc,matD2,labels,cv=cv)\n",
    "    scores_all[:,r] = np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#################################### CROSS VALIDATION ######################################\n",
    "\n",
    "# Cross Validation\n",
    "cv = KFold(n=len(X), n_folds=5, shuffle=True)\n",
    "cv_scores = cross_val_score(svc, Xvars, labels, cv=cv, scoring='f1') # scoring optional\n",
    "np.mean(cv_scores)\n",
    "\n",
    "########################################## ICA ############################################\n",
    "\n",
    "# CanICA\n",
    "\n",
    "canica = CanICA(n_components=25,smoothing_fwhm = 6., memory = \"nilearn_cache\", memory_level=5, threshold=3., verbose=10, random_state=0) #smoothing can be None\n",
    "canica.fit(func_filenames) # full path to list of nii.gz files\n",
    "\n",
    "components_img = canica.masker_.inverse_transform(canica.components_) # makes nifti object\n",
    "components_img.to_filename('canica_resting_state.nii.gz')\n",
    "\n",
    "plot_prob_atlas(components_img, title = \"All ICA Components\", view_type = \"filled_contours\")\n",
    "\n",
    "\n",
    "######################################### OTHER ###########################################\n",
    "\n",
    "# Measure chance level\n",
    "null_cv_scores = cross_val_score(DummyClassifier(), X, labels, cv=cv)\n",
    "\n",
    "# Permutation tests\n",
    "null_cv_scores = permutation_test_score(svc, X, target, cv=cv)\n",
    "\n",
    "# Save matlab file.\n",
    "sio.savemat(mypath + 'matfile.mat',{'matvar':pyvar})\n",
    "\n",
    "# Save a model using pickle or joblib\n",
    "s = pickle.dumps(svc)\n",
    "svc2 = pickle.loads(s)\n",
    "joblib.dump(svc, 'filename.pkl')\n",
    "svc2 = joblib.load('filename.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'n_features_to_select'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-c00267cf7b13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mrfe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRFE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features_to_select\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'pinfo RFECV'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mrfecv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRFECV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features_to_select\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mmlmat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmat1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mfeatscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmlmat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmlmat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'n_features_to_select'"
     ]
    }
   ],
   "source": [
    "svc = SVC(kernel='linear', C=1.)\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "# RFE\n",
    "rfe = RFE(estimator = svc, n_features_to_select = 100, step=.1)\n",
    "RFECV?\n",
    "rfecv = RFECV(estimator = svc, n_features_to_select = 100, step = 100)\n",
    "mlmat = mat1\n",
    "featscores = np.zeros([np.shape(mlmat)[0],np.shape(mlmat)[1]])\n",
    "scores = list()\n",
    "inds = np.arange(46)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-21-52aef95985a6>, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-21-52aef95985a6>\"\u001b[0;36m, line \u001b[0;32m12\u001b[0m\n\u001b[0;31m    inds2 = (inds!=i)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "for i in range(46):\n",
    "    print \"Subject\", i+1\n",
    "        inds2 = (inds!=i)\n",
    "        X = mlmat[inds2,:]\n",
    "        y = labels[inds2]\n",
    "        Xtrain, Xcv, Ytrain, Ycv = train_test_split(matD2,labels2,test_size = 0.33, random_state=42)\n",
    "        rfecv.fit(Xtrain,Ytrain)\n",
    "        feats = find(rfe.ranking_==1)\n",
    "        test = mlmat[i,:].reshape(1,-1)\n",
    "        tempscore = rfe.predict(test)\n",
    "        scores.append(tempscore[0])\n",
    "        featscores[i,feats] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
